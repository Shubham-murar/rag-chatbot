import streamlit as st
from chatbot import get_answer, log_to_arize
from qdrant_client import QdrantClient
from langchain_community.vectorstores import Qdrant as LCQdrant
from langchain_community.embeddings import HuggingFaceEmbeddings

# ğŸ”¹ Initialize Streamlit App
st.set_page_config(page_title="AI Clone Chatbot", layout="wide")
st.title("ğŸ¤– AI Clone Chatbot")

# ğŸ”¹ Initialize Qdrant Client (Persistent Storage)
collection_name = "ai_clone"
client = QdrantClient(path="qdrant_db", force_disable_lock=True)  # âœ… Opens Qdrant in read-only mode

# ğŸ”¹ Initialize Retriever
hf_embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
retriever = LCQdrant(client, collection_name, hf_embeddings.embed_query).as_retriever(search_kwargs={"k": 3})

# ğŸ”¹ User Input
user_input = st.text_input("Ask me anything about AI:")

if user_input:
    response = get_answer(user_input)

    # ğŸ”¹ Show chatbot response
    st.subheader("ğŸ¤– AI Response:")
    st.write(response)

    # ğŸ”¹ Show retrieved knowledge sources
    with st.sidebar:
        st.subheader("ğŸ” Retrieved Sources")
        docs = retriever.invoke(user_input)
        for doc in docs:
            st.write(f"- {doc.page_content[:200]}...")  # Show snippet

    # ğŸ”¹ User Feedback for Logging
    feedback = st.radio("Was this answer helpful?", ("ğŸ‘ Yes", "ğŸ‘ No"))

    # Logging Feedback to Arize
    actual_label = response if feedback == "ğŸ‘ Yes" else "INCORRECT"
    log_to_arize(user_input, response, actual_label)

    st.success("âœ… Your feedback has been recorded!")

